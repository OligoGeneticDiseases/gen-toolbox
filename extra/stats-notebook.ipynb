{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Gen-Toolbox data analyis notebook\n",
    "\n",
    "This notebook is part of the gen-toolbox project, a comprehensive tool designed for collating large numbers of VCF files from unique samples, annotating variants, and creating variant frequency tables. The project is tailored to run on substantial servers and has been spearheaded by the Tartu University Hospital Centre of Medical Genetics and the Tartu University Institute of Clinical Medicine, with the backing of the Estonian Research Council grant PSG774.\n",
    "\n",
    "## Notebook Objective:\n",
    "\n",
    "This particular notebook delves into the statistical analysis of Single Nucleotide Variants (SNVs) in genomic data. The aim is to:\n",
    "\n",
    "- Load and process the combined frequency tables created from a large number of (g)VCF samples with the main Hail wrapper.\n",
    "- Compute statistical metrics and burden ratios.\n",
    "- Visualize results for a graphical analysis of the data.\n",
    "\n",
    "## Prerequisites:\n",
    "\n",
    "1. **Data Preparation**: Ensure you have the necessary VCF files and gene configurations. The notebook expects CSV or TSV formatted files.\n",
    "\n",
    "2. **Environment Setup**: If using Docker, ensure Docker is installed and running. Alternatively, ensure you have a Python environment set up with all necessary libraries.\n",
    "\n",
    "3. **Configuration**: Adjust path variables in the notebook to match the location of your data files. Jupyter notebooks detect data only from the same folder as the notebook itself (due to portability of notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 0. Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "import scipy.stats as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "import numpy as np\n",
    "# Pandas version 1.24 required for hail, significant speed improvement in 2.0.X however\n",
    "import pandas as pd\n",
    "# Use modin as a pandas substitute for improved speeds\n",
    "#import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Path variables - change these for specifing correct paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_config = \"/mnt/c/Users/ville/Documents/PycharmProjects/gen-toolbox/src/config/gene_config.json\"\n",
    "args_case =  \"/mnt/c/Users/ville/OneDrive - Tartu Ülikool/Doktorantuur/Oligogeensus/Frequency_databases/frequency_table_643_LIHAS_positive.csv\" # add here TSV or CSV file with case data\n",
    "args_control = \"/mnt/c/Users/ville/OneDrive - Tartu Ülikool/Doktorantuur/Oligogeensus/Frequency_databases/frequency_table_9099_LIHAS_negative.csv\" # add here TSV or CSV file with control data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_csv = True # if False, then tsv, if True, then csv\n",
    "iterations = 1000000 # number of iterations for permutation test\n",
    "combination_length=10 # number of genes in a set\n",
    "case_genes_length = combination_length  # e.g. sets of 5 genes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gene_config(json_file):\n",
    "    \"\"\"Load gene configuration from a JSON file.\"\"\"\n",
    "    p = pathlib.Path(json_file)\n",
    "    config = json.loads(p.read_bytes())\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number_from_filename(filename: str) -> int:\n",
    "    \"\"\"Extract the number from the given filename.\"\"\"\n",
    "    match = re.search(r\"\\d+\", filename)\n",
    "    return int(match.group()) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_count = extract_number_from_filename(args_case) # extract number from filename\n",
    "control_count = extract_number_from_filename(args_control) # extract number from filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Loading Gene config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_gene_config(gene_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['store_data', 'intersect_genes_tso', 'intersect_genes_tshc', 'neg_control_genes', 'rv_genes'])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keys in gene_config would show information present in it\n",
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['A2M', 'A4GALT', 'A4GNT', 'AAAS', 'AADAC']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets Show some of itersect genes\n",
    "config['intersect_genes_tso'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4811"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many intersect genes are there\n",
    "len(config['intersect_genes_tso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4811\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "# printing number of genes in each conf\n",
    "for conf in [config[\"intersect_genes_tso\"], config[\"intersect_genes_tshc\"]]:\n",
    "    print(len(conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Getting rv_genes and neg_control_genes for use in our test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_genes = config[\"rv_genes\"]\n",
    "neg_control_genes = config[\"neg_control_genes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Loading case and control SNV data\n",
    "\n",
    "For csv data file intersect_genes_tso is loaded while for tsv intersect_genes_tshc is loaded. Read the docs for clarification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_csv:\n",
    "    intersect_genes = config[\"intersect_genes_tso\"]\n",
    "    df_case = pd.read_csv(args_case, sep=\",\", header=0)\n",
    "    df_control = pd.read_csv(args_control, sep=\",\", header=0)\n",
    "else:\n",
    "    intersect_genes = config[\"intersect_genes_tshc\"]\n",
    "    df_case = pd.read_table(args_case, sep=\"\\t\", header=0)\n",
    "    df_control = pd.read_table(args_control, sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have loaded single file for case and control, both dataframes will be same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  Unnamed: 0  HIGH.gnomad_1  HIGH.gnomad_1_5  HIGH.gnomad_5_100  \\\n0        A2M              0                0                167   \n1      A4GNT              4                0                  0   \n\n   MODERATE.gnomad_1  MODERATE.gnomad_1_5  MODERATE.gnomad_5_100  \\\n0                 12                   19                   1785   \n1                  9                   18                    775   \n\n   LOW.gnomad_1  LOW.gnomad_1_5  LOW.gnomad_5_100  MODIFIER.gnomad_1  \\\n0             4               6               326                  8   \n1             6               2              1545                  0   \n\n   MODIFIER.gnomad_1_5  MODIFIER.gnomad_5_100  \n0                    0                    694  \n1                    0                      6  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>HIGH.gnomad_1</th>\n      <th>HIGH.gnomad_1_5</th>\n      <th>HIGH.gnomad_5_100</th>\n      <th>MODERATE.gnomad_1</th>\n      <th>MODERATE.gnomad_1_5</th>\n      <th>MODERATE.gnomad_5_100</th>\n      <th>LOW.gnomad_1</th>\n      <th>LOW.gnomad_1_5</th>\n      <th>LOW.gnomad_5_100</th>\n      <th>MODIFIER.gnomad_1</th>\n      <th>MODIFIER.gnomad_1_5</th>\n      <th>MODIFIER.gnomad_5_100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A2M</td>\n      <td>0</td>\n      <td>0</td>\n      <td>167</td>\n      <td>12</td>\n      <td>19</td>\n      <td>1785</td>\n      <td>4</td>\n      <td>6</td>\n      <td>326</td>\n      <td>8</td>\n      <td>0</td>\n      <td>694</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A4GNT</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>18</td>\n      <td>775</td>\n      <td>6</td>\n      <td>2</td>\n      <td>1545</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_case.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  Unnamed: 0  HIGH.gnomad_1  HIGH.gnomad_1_5  HIGH.gnomad_5_100  \\\n0        A2M              1                0               2548   \n1      A2ML1              2                0                  6   \n\n   MODERATE.gnomad_1  MODERATE.gnomad_1_5  MODERATE.gnomad_5_100  \\\n0                172                  266                  25005   \n1                  2                    0                    337   \n\n   LOW.gnomad_1  LOW.gnomad_1_5  LOW.gnomad_5_100  MODIFIER.gnomad_1  \\\n0            82              81              4818                 74   \n1             0               1               210                  1   \n\n   MODIFIER.gnomad_1_5  MODIFIER.gnomad_5_100  \n0                    3                   9017  \n1                    0                    155  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>HIGH.gnomad_1</th>\n      <th>HIGH.gnomad_1_5</th>\n      <th>HIGH.gnomad_5_100</th>\n      <th>MODERATE.gnomad_1</th>\n      <th>MODERATE.gnomad_1_5</th>\n      <th>MODERATE.gnomad_5_100</th>\n      <th>LOW.gnomad_1</th>\n      <th>LOW.gnomad_1_5</th>\n      <th>LOW.gnomad_5_100</th>\n      <th>MODIFIER.gnomad_1</th>\n      <th>MODIFIER.gnomad_1_5</th>\n      <th>MODIFIER.gnomad_5_100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A2M</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2548</td>\n      <td>172</td>\n      <td>266</td>\n      <td>25005</td>\n      <td>82</td>\n      <td>81</td>\n      <td>4818</td>\n      <td>74</td>\n      <td>3</td>\n      <td>9017</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A2ML1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>337</td>\n      <td>0</td>\n      <td>1</td>\n      <td>210</td>\n      <td>1</td>\n      <td>0</td>\n      <td>155</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_control.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "('number of genes in case: 6758', 'number of genes in control: 19313')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe length\n",
    "# Each row contains a gene\n",
    "f'number of genes in case: {len(df_case)}', f'number of genes in control: {len(df_control)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Assigning the 1st column the name of gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case.rename(columns={df_case.columns[0]: \"gene\"}, inplace = True)\n",
    "df_control.rename(columns={df_control.columns[0]: \"gene\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['gene', 'HIGH.gnomad_1', 'HIGH.gnomad_1_5', 'HIGH.gnomad_5_100',\n       'MODERATE.gnomad_1', 'MODERATE.gnomad_1_5', 'MODERATE.gnomad_5_100',\n       'LOW.gnomad_1', 'LOW.gnomad_1_5', 'LOW.gnomad_5_100',\n       'MODIFIER.gnomad_1', 'MODIFIER.gnomad_1_5', 'MODIFIER.gnomad_5_100'],\n      dtype='object')"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_case.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Getting list of all genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genes = df_case['gene']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Selecting intersect gene from config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only itersecting genes from config\n",
    "if intersect_genes is not None:\n",
    "    # Filter out empty genes and keep only the intersecting genes in both dataframes\n",
    "    df_case = df_case.dropna(subset=[\"gene\"])\n",
    "    df_case = df_case[df_case.gene.isin(intersect_genes)]\n",
    "    df_control = df_control.dropna(subset=[\"gene\"])\n",
    "    df_control = df_control[df_control.gene.isin(intersect_genes)]\n",
    "    df_case.reset_index(drop=True, inplace=True)\n",
    "    df_control.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "('number of genes in case: 4674', 'number of genes in control: 4695')"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe length after selecting only intersecting genes available in config\n",
    "f'number of genes in case: {len(df_case)}', f'number of genes in control: {len(df_control)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Case dataframe length does not match control dataframe length! The intersect of both dataframes will be analysed.\n"
     ]
    }
   ],
   "source": [
    "#Check if dataframes are of equal length\n",
    "if len(df_case.index) != len(df_control.index):\n",
    "    print(\"WARNING: Case dataframe length does not match control dataframe length! The intersect of both dataframes will be analysed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Taking intersect of both data frames and sorting on gene column\n",
    "\n",
    "This step is performed to ensure that same genes for case and control are present and we can apply indexwise operation in our statistical test. Randomly selected indices will produce same genes from both data frames.\n",
    "\n",
    "Sorting is done because if we select gene names randomly and then filter both dataframes for selected gene names then it will be a slow process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the intersect of two dataframes based on gene column\n",
    "intersection_values = set(df_case['gene']).intersection(df_control['gene'])\n",
    "df_case = df_case[df_case[\"gene\"].isin(intersection_values)]\n",
    "df_case = df_case.sort_values(by=\"gene\")\n",
    "df_case = df_case.fillna(0)\n",
    "df_control = df_control[df_control[\"gene\"].isin(intersection_values)]\n",
    "df_control = df_control.sort_values(by=\"gene\")\n",
    "df_control = df_control.fillna(0)\n",
    "df_case.reset_index(drop=True, inplace=True)\n",
    "df_control.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rows must match in order to do index based math\n",
    "assert df_case[\"gene\"].equals(df_control[\"gene\"]), \"Case and control dataframe indices do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Initializing empty dataframes to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_results_1 = pd.DataFrame()\n",
    "fraction_results_2 = pd.DataFrame(columns=df_case.columns[1:].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Calculating desired variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have passed only 1 file it will make expected_ratio to be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case means \n",
      "HIGH.gnomad_1              0.707254\n",
      "HIGH.gnomad_1_5            0.424995\n",
      "HIGH.gnomad_5_100         11.141879\n",
      "MODERATE.gnomad_1         11.996790\n",
      "MODERATE.gnomad_1_5       14.566660\n",
      "MODERATE.gnomad_5_100    482.994650\n",
      "LOW.gnomad_1               9.161352\n",
      "LOW.gnomad_1_5            13.204579\n",
      "LOW.gnomad_5_100         820.236465\n",
      "MODIFIER.gnomad_1          2.869463\n",
      "MODIFIER.gnomad_1_5        4.104002\n",
      "MODIFIER.gnomad_5_100    228.691419\n",
      "dtype: float64\n",
      "Control means \n",
      "HIGH.gnomad_1                9.683287\n",
      "HIGH.gnomad_1_5              5.947143\n",
      "HIGH.gnomad_5_100          157.160068\n",
      "MODERATE.gnomad_1          166.510593\n",
      "MODERATE.gnomad_1_5        205.203938\n",
      "MODERATE.gnomad_5_100     6797.204152\n",
      "LOW.gnomad_1               127.010486\n",
      "LOW.gnomad_1_5             183.816606\n",
      "LOW.gnomad_5_100         11531.893644\n",
      "MODIFIER.gnomad_1           36.959555\n",
      "MODIFIER.gnomad_1_5         52.137599\n",
      "MODIFIER.gnomad_5_100     2935.227477\n",
      "dtype: float64\n",
      "Expected ratio cases / controls: 0.07066710627541488, log2 -3.8228173560173797\n",
      "Expected ratio cases / controls by group (log2): \n",
      " HIGH.gnomad_1           -3.775196\n",
      "HIGH.gnomad_1_5         -3.806680\n",
      "HIGH.gnomad_5_100       -3.818170\n",
      "MODERATE.gnomad_1       -3.794894\n",
      "MODERATE.gnomad_1_5     -3.816316\n",
      "MODERATE.gnomad_5_100   -3.814862\n",
      "LOW.gnomad_1            -3.793243\n",
      "LOW.gnomad_1_5          -3.799157\n",
      "LOW.gnomad_5_100        -3.813446\n",
      "MODIFIER.gnomad_1       -3.687095\n",
      "MODIFIER.gnomad_1_5     -3.667221\n",
      "MODIFIER.gnomad_5_100   -3.681998\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_237/2646775162.py:7: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_case_mean = df_case.mean()\n",
      "/tmp/ipykernel_237/2646775162.py:8: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_control_mean = df_control.mean()\n"
     ]
    }
   ],
   "source": [
    "expected_ratio = case_count / control_count\n",
    "df_case.reset_index(drop=True, inplace=True)\n",
    "df_control.reset_index(drop=True, inplace=True)\n",
    "columns_to_add = df_case.columns[1:]\n",
    "\n",
    "# Calculate the mean of the case and control dataframes\n",
    "df_case_mean = df_case.mean()\n",
    "df_control_mean = df_control.mean()\n",
    "\n",
    "num_columns = df_case.shape[1]\n",
    "\n",
    "print(\"Case means \\n{0}\\nControl means \\n{1}\".format(df_case_mean, df_control_mean))\n",
    "print(\"Expected ratio cases / controls: {0}, log2 {1}\".format(expected_ratio, np.log2(expected_ratio)))\n",
    "print(\"Expected ratio cases / controls by group (log2): \\n {0}\".format(np.log2(df_case_mean / df_control_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisible columns, look at the ratios grossly\n",
    "divison_result_gross = df_case[columns_to_add] / df_control[columns_to_add]\n",
    "r = divison_result_gross[divison_result_gross[:-1] > expected_ratio].dropna(how=\"all\")\n",
    "r[\"gene\"] = df_case[\"gene\"]  ## Do nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Random selection of indices for statistical test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "indices = np.array([np.random.choice(df_case.index, size=case_genes_length, replace=False) for _ in range(iterations)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Taking sum for columns against selected indices for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the sum of total variants for the case and control groups using the sampled indices\n",
    "total_variants_case = np.array([df_case.iloc[idx, 1:].sum().to_numpy() for idx in indices])\n",
    "total_variants_control = np.array([df_control.iloc[idx, 1:].sum().to_numpy() for idx in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Show what a single burden event looks like\n",
    "total_variants_case\n",
    "total_variants_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Ratios vector for each column based on given condition to include sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ratios_vector = np.where(np.logical_and(total_variants_case > 1, total_variants_control > 1),\\\n",
    "                total_variants_case / total_variants_control,\\\n",
    "                np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# numer of iterations and column number can be seen in shape\n",
    "ratios_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Where sum is less than 1 NaN will be placed for the ratio in that\n",
    "ratios_vector[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Satisfying below statistical condition to get burden events\n",
    "Low variant count events are not statistically significants.\n",
    "I.e. gene sets containing only a few variants or variants in only one gene are excluded.\n",
    "High variant burdens are expected between impactful genes in the different groups.\n",
    "\n",
    "\n",
    "\n",
    "1. $$ \\log_2\\left(\\frac{\\text{ratios\\_vector}}{\\text{expected\\_ratio}}\\right) > log2(99th\\_percentile) $$\n",
    "\n",
    "\n",
    "2. $$ \\text{total\\_variants\\_case} > \\text{case\\_genes\\_length} $$\n",
    "\n",
    "\n",
    "3. $$ \\text{total\\_variants\\_control} > \\text{case\\_genes\\_length} $$\n",
    "\n",
    "4. $$ \\text{ Nonzero values total\\_variants\\_control} > 1 $$\n",
    "\n",
    "5. $$ \\text{ Nonzero values total\\_variants\\_case} > 1 $$\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove rows where there are only single values in a burden event (i.e. [0, 0, 0, 0.4])\n",
    "# Because we are looking for interactions between genes\n",
    "def count_zeros(arr):\n",
    "    return np.greater_equal(sum(1 for x in arr if (x == 0 or np.isnan(x))), combination_length-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fraction_results_tmp = pd.DataFrame(ratios_vector, columns=df_case.columns[1:].tolist())\n",
    "\n",
    "complex_condition = (\n",
    "    (np.log2(ratios_vector/expected_ratio) > 0.2) & # Early filtering to reduce about 75% of data\n",
    "    (total_variants_case > case_genes_length) &\n",
    "    (total_variants_control > case_genes_length) &\n",
    "    (np.count_nonzero(~np.isnan(total_variants_control)) > 1) &\n",
    "    (np.count_nonzero(~np.isnan(total_variants_case)) > 1)\n",
    "                    ).T.flatten()\n",
    "\n",
    "gene = np.array([df_case.gene[idx].to_numpy() for idx in indices])\n",
    "gene = np.tile(gene, (len(df_case.columns[1:].tolist()),1))\n",
    "case = np.array([df_case.iloc[idx, 1:].to_numpy().T for idx in indices]).transpose((1, 0, 2))\n",
    "control = np.array([df_control.iloc[idx, 1:].to_numpy().T for idx in indices]).transpose((1, 0, 2))\n",
    "\n",
    "case = case.reshape((-1, case.shape[-1]))\n",
    "control = control.reshape((-1, control.shape[-1]))\n",
    "case_control = case/control\n",
    "gene_case_control = np.dstack((gene, case_control)) # Make a nested object combining ratios to genes, exploded later in section 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fraction_results_1 = pd.DataFrame()\n",
    "fraction_results_1['frequency_bin'] = np.repeat(fraction_results_tmp.columns, len(fraction_results_tmp))\n",
    "fraction_results_1['burden_ratio'] = fraction_results_tmp.to_numpy().T.flatten()\n",
    "fraction_results_1[\"burden_ratio_norm\"] = fraction_results_1['burden_ratio'].div(expected_ratio)\n",
    "fraction_results_1[\"burden_ratio_norm_log2\"] = np.log2(fraction_results_1['burden_ratio_norm'])\n",
    "fraction_results_1['gene'] = list(gene)\n",
    "fraction_results_1['case'] = list(case)\n",
    "fraction_results_1['control'] = list(control)\n",
    "fraction_results_1['case_control'] = list(case_control)\n",
    "fraction_results_1['case_control_gene'] = list(gene_case_control)\n",
    "\n",
    "# Filter out a large amount of low ratio or low variant count burdens\n",
    "fraction_results_1 = fraction_results_1[complex_condition].reset_index(drop=True)\n",
    "\n",
    "### THIS WILL FILTER SINGLE GENE EVENTS\n",
    "fraction_results_1 = fraction_results_1[~fraction_results_1[\"case_control\"].apply(count_zeros)]\n",
    "### THIS WILL FILTER SINGLE GENE EVENTS\n",
    "\n",
    "\n",
    "fraction_results_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Verify True and False condition indexes\n",
    "#print(list(complex_condition))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Storing Dataframe\n",
    "Normalise ratios with the expected ratio (expected mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fraction_results_2 = pd.DataFrame(ratios_vector/expected_ratio, columns=df_case.columns[1:].tolist())\n",
    "if config[\"store_data\"]:\n",
    "    fraction_results_2.to_pickle(\"{0}_{1}_{2}_forgraph.pkl\".format(case_count, control_count, iterations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Plotting the burden events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#fraction_results_2 = pd.read_pickle(\"{0}_{1}_{2}_forgraph.pkl\".format(case_count, control_count, iterations))\n",
    "df_99 = pd.DataFrame([\"frequency_bin\", \"99th_quantile\"])\n",
    "fig, axs = plt.subplots(\n",
    "    len(fraction_results_2.columns),\n",
    "    1,\n",
    "    sharex=\"none\",\n",
    "    tight_layout=False,\n",
    "    figsize=(12, 24),\n",
    "    facecolor='xkcd:mint green',\n",
    ")\n",
    "i = 0\n",
    "for frequency_column in fraction_results_2.columns:\n",
    "    fraction_results_2[frequency_column].dropna(inplace=True)\n",
    "\n",
    "    if fraction_results_2[frequency_column].any():\n",
    "        # Average sample normalization enrichment ratios for \"likely impactful\" and \"likely non-impactful\" genes\n",
    "        q_avg = np.divide(\n",
    "            np.sum(df_case[df_case.gene.isin(rv_genes)][frequency_column]),\n",
    "            np.sum(df_control[df_control.gene.isin(rv_genes)][frequency_column]),)\n",
    "        q_avg_control_group = np.divide(\n",
    "            np.sum(df_case[df_case.gene.isin(neg_control_genes)][frequency_column]),\n",
    "            np.sum(\n",
    "                df_control[df_control.gene.isin(neg_control_genes)][frequency_column]),)\n",
    "        print(\n",
    "            \"Impact group (av-norm. ): {0}, case_genes_enrichment: {1}, control_genes_enrichment: {2}\".format(\n",
    "                frequency_column, q_avg, q_avg_control_group\n",
    "            )\n",
    "        )\n",
    "        fraction_results_2[frequency_column + \"log2\"] = np.log2(\n",
    "            fraction_results_2[frequency_column]).dropna()\n",
    "\n",
    "\n",
    "        # Unused block\n",
    "        mu, std = sp.norm.fit(fraction_results_2[frequency_column].dropna())\n",
    "        percentile_99 = np.percentile(fraction_results_2[frequency_column + \"log2\"].dropna(), 99)\n",
    "        xmin, xmax = (\n",
    "            fraction_results_2[frequency_column].min(),\n",
    "            fraction_results_2[frequency_column].dropna().max(),\n",
    "        )\n",
    "        x = np.linspace(mu - 3 * std, mu + 3*std, 100)\n",
    "        _, bins, _ = axs[i].hist(\n",
    "            fraction_results_2[frequency_column + \"log2\"],\n",
    "            density=False,\n",
    "            log=False,\n",
    "            histtype=\"stepfilled\",\n",
    "            stacked=True,\n",
    "            bins=500,\n",
    "        )\n",
    "        p = sp.norm.pdf(bins, mu, std)\n",
    "        axs[i].set_title(\n",
    "            \"{0}: mean_enrichment={1} positive_genes={2} negative_genes={3} 99th percentile (purple)={4}\".format(\n",
    "                fraction_results_2[frequency_column].name  + \"_log2\",\n",
    "                np.round(fraction_results_2[frequency_column].mean(), 2),\n",
    "                np.round(np.log2(q_avg), 2),\n",
    "                np.round(np.log2(q_avg_control_group), 2),\n",
    "                np.round(percentile_99, 2)\n",
    "                )\n",
    "        )\n",
    "        axs[i].axvline(percentile_99, color=\"purple\")\n",
    "        df_99[frequency_column] = np.round(percentile_99, 2)\n",
    "        i +=1\n",
    "plt.show()\n",
    "print(\"Done {0} iterations\".format(iterations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Transform the 99th percentiles into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_99 = df_99.drop(df_99.index[0])\n",
    "df_99 = df_99.T\n",
    "df_99.columns = df_99.iloc[0]\n",
    "df_99 = df_99[1:]\n",
    "\n",
    "# See the 99th percentile in log2 for all simulations without the filters applied:\n",
    "df_99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 Plotting high burden events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take in high value burden events and filter out genes from gene sets that actually contribute to the burden event,\n",
    "keep only impactful (i.e. above 99th percentile) events and plot the times the gene has appeared in burden events against highest event, keep only genes that appear more than 40 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fraction_results_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df = fraction_results_1\n",
    "df[\"impactful_bool\"] = df.apply(lambda row: row.loc[\"burden_ratio_norm_log2\"] > df_99.loc[row.loc[\"frequency_bin\"]], axis=1) #slow\n",
    "df = df[df.impactful_bool]\n",
    "\n",
    "df = df.explode(\"case_control_gene\") # Slow due explode by size of gene_set\n",
    "\n",
    "df = df[~df[\"case_control_gene\"].apply(lambda x: any(pd.isna(case_control_gene) or case_control_gene == 0 for case_control_gene in x))]\n",
    "df[[\"impactful_gene\", \"impactful_burden\"]] = df[\"case_control_gene\"].tolist()\n",
    "# Add some summary statistics about burden events\n",
    "df2 = df.merge(df.groupby([\"frequency_bin\", \"impactful_gene\"])[\"burden_ratio\"].aggregate([pd.Series.count]).reset_index())\n",
    "# Filter out rare occurrences of high burden (correlating to miniscule bumps above 99th percentile on the main plot)\n",
    "df2 = df2[df2[\"count\"]>30]\n",
    "df2.sort_values(\"burden_ratio_norm_log2\", ascending=False, inplace=True)\n",
    "df2.drop_duplicates(subset=\"impactful_gene\", inplace=True)\n",
    "df2.sort_values(\"frequency_bin\", inplace=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Save high value burden events data to csv"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Store data\n",
    "if config[\"store_data\"]:\n",
    "    df.to_csv(\"{0}_{1}_{2}.csv\".format(case_count, control_count, iterations))\n",
    "    df.to_pickle(\"{0}_{1}_{2}.pkl\".format(case_count, control_count, iterations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2  Plot relevant genes in each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#df = pd.read_pickle(\"{0}_{1}_{2}.pkl\".format(case_count, control_count, iterations))\n",
    "\n",
    "# Plot data, output is max 12 plots for every frequency bin.\n",
    "genes = []\n",
    "for frequency_column in fraction_results_2.columns:\n",
    "    filtered_df = df2[df2[\"frequency_bin\"] == frequency_column]\n",
    "    if filtered_df.shape[0] > 0:\n",
    "        #plt.scatter(data=filtered_df[\"gene\"], x=filtered_df[\"case_control\"], y=filtered_df[\"burden_ratio\"])\n",
    "\n",
    "        ax = filtered_df.plot(x='count', y='burden_ratio_norm_log2', kind='scatter', figsize=(5, 5),\n",
    "                              title=frequency_column, legend=\"impactful_gene\", facecolor='white', marker=\" \")\n",
    "        texts = []\n",
    "        filtered_df[['count', 'burden_ratio_norm_log2', 'impactful_gene']].apply(lambda x: texts.append(ax.text(*x, color=\"red\")), axis=1)\n",
    "        adjust_text(texts, arrowprops=dict(arrowstyle=\"-\", color='b', lw=0.2), time_lim=5, ax=ax)\n",
    "        genes.append([frequency_column, texts])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Useful to see g:Profiles for these genes\n",
    "for name, graph in genes:\n",
    "    print(name)\n",
    "    for text in graph:\n",
    "        print(text.get_text())\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "important_genes = [\"GLE1\", \"TWIST1\", \"FANCB\", \"RDH12\", \"NPR3\", \"FAAH2\", \"XPNPEP3\", \"AGA\", \"DIP2B\", \"SNIP1\", \"NCKAP1\"]\n",
    "#df = df[df[\"impactful_gene\"].apply(lambda x: x in important_genes)]\n",
    "\n",
    "import itertools\n",
    "for pair in (list(itertools.combinations(df[\"impactful_gene\"], 2))):\n",
    "    print(\"{0},{1}\".format(pair, sum(set(pair).issubset(set(row)) for row in df['gene'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
