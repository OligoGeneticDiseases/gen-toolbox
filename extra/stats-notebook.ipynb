{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Gen-Toolbox data analyis notebook\n",
    "\n",
    "This notebook is part of the gen-toolbox project, a comprehensive tool designed for collating large numbers of VCF files from unique samples, annotating variants, and creating variant frequency tables. The project is tailored to run on substantial servers and has been spearheaded by the Tartu University Hospital Centre of Medical Genetics and the Tartu University Institute of Clinical Medicine, with the backing of the Estonian Research Council grant PSG774.\n",
    "\n",
    "## Notebook Objective:\n",
    "\n",
    "This particular notebook delves into the statistical analysis of Single Nucleotide Variants (SNVs) in genomic data. The aim is to:\n",
    "\n",
    "- Load and process the combined frequency tables created from a large number of (g)VCF samples with the main Hail wrapper.\n",
    "- Compute statistical metrics and burden ratios.\n",
    "- Visualize results for a graphical analysis of the data.\n",
    "\n",
    "## Prerequisites:\n",
    "\n",
    "1. **Data Preparation**: Ensure you have the necessary VCF files and gene configurations. The notebook expects CSV or TSV formatted files.\n",
    "\n",
    "2. **Environment Setup**: If using Docker, ensure Docker is installed and running. Alternatively, ensure you have a Python environment set up with all necessary libraries.\n",
    "\n",
    "3. **Configuration**: Adjust path variables in the notebook to match the location of your data files. Jupyter notebooks detect data only from the same folder as the notebook itself (due to portability of notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 0. Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "import scipy.stats as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "import numpy as np\n",
    "# Pandas version 1.24 required for hail, significant speed improvement in 2.0.X however\n",
    "import pandas as pd\n",
    "# Use modin as a pandas substitute for improved speeds\n",
    "#import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Path variables - change these for specifing correct paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_config = \"/mnt/c/Users/ville/Documents/PycharmProjects/gen-toolbox/src/config/gene_config.json\"\n",
    "args_case =  \"/mnt/c/Users/ville/OneDrive - Tartu Ülikool/Doktorantuur/Oligogeensus/Frequency_databases/frequency_table_643_LIHAS_positive.csv\" # add here TSV or CSV file with case data\n",
    "args_control = \"/mnt/c/Users/ville/OneDrive - Tartu Ülikool/Doktorantuur/Oligogeensus/Frequency_databases/frequency_table_9099_LIHAS_negative.csv\" # add here TSV or CSV file with control data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_csv = True # if False, then tsv, if True, then csv\n",
    "iterations = 300000 # number of iterations for permutation test\n",
    "combination_length=3 # number of genes in a set\n",
    "case_genes_length = combination_length  # e.g. sets of 5 genes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gene_config(json_file):\n",
    "    \"\"\"Load gene configuration from a JSON file.\"\"\"\n",
    "    p = pathlib.Path(json_file)\n",
    "    config = json.loads(p.read_bytes())\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number_from_filename(filename: str) -> int:\n",
    "    \"\"\"Extract the number from the given filename.\"\"\"\n",
    "    match = re.search(r\"\\d+\", filename)\n",
    "    return int(match.group()) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_count = extract_number_from_filename(args_case) # extract number from filename\n",
    "control_count = extract_number_from_filename(args_control) # extract number from filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Loading Gene config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_gene_config(gene_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys in gene_config would show information present in it\n",
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Show some of itersect genes\n",
    "config['intersect_genes_tso'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many intersect genes are there\n",
    "len(config['intersect_genes_tso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing number of genes in each conf\n",
    "for conf in [config[\"intersect_genes_tso\"], config[\"intersect_genes_tshc\"]]:\n",
    "    print(len(conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Getting rv_genes and neg_control_genes for use in our test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_genes = config[\"rv_genes\"]\n",
    "neg_control_genes = config[\"neg_control_genes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Loading case and control SNV data\n",
    "\n",
    "For csv data file intersect_genes_tso is loaded while for tsv intersect_genes_tshc is loaded. Read the docs for clarification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_csv:\n",
    "    intersect_genes = config[\"intersect_genes_tso\"]\n",
    "    df_case = pd.read_csv(args_case, sep=\",\", header=0)\n",
    "    df_control = pd.read_csv(args_control, sep=\",\", header=0)\n",
    "else:\n",
    "    intersect_genes = config[\"intersect_genes_tshc\"]\n",
    "    df_case = pd.read_table(args_case, sep=\"\\t\", header=0)\n",
    "    df_control = pd.read_table(args_control, sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have loaded single file for case and control, both dataframes will be same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe length\n",
    "# Each row contains a gene\n",
    "f'number of genes in case: {len(df_case)}', f'number of genes in control: {len(df_control)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Assigning the 1st column the name of gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case.rename(columns={df_case.columns[0]: \"gene\"}, inplace = True)\n",
    "df_control.rename(columns={df_control.columns[0]: \"gene\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Getting list of all genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genes = df_case['gene']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Selecting intersect gene from config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only itersecting genes from config\n",
    "if intersect_genes is not None:\n",
    "    # Filter out empty genes and keep only the intersecting genes in both dataframes\n",
    "    df_case = df_case.dropna(subset=[\"gene\"])\n",
    "    df_case = df_case[df_case.gene.isin(intersect_genes)]\n",
    "    df_control = df_control.dropna(subset=[\"gene\"])\n",
    "    df_control = df_control[df_control.gene.isin(intersect_genes)]\n",
    "    df_case.reset_index(drop=True, inplace=True)\n",
    "    df_control.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe length after selecting only intersecting genes available in config\n",
    "f'number of genes in case: {len(df_case)}', f'number of genes in control: {len(df_control)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if dataframes are of equal length\n",
    "if len(df_case.index) != len(df_control.index):\n",
    "    print(\"WARNING: Case dataframe length does not match control dataframe length! The intersect of both dataframes will be analysed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Taking intersect of both data frames and sorting on gene column\n",
    "\n",
    "This step is performed to ensure that same genes for case and control are present and we can apply indexwise operation in our statistical test. Randomly selected indices will produce same genes from both data frames.\n",
    "\n",
    "Sorting is done because if we select gene names randomly and then filter both dataframes for selected gene names then it will be a slow process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the intersect of two dataframes based on gene column\n",
    "intersection_values = set(df_case['gene']).intersection(df_control['gene'])\n",
    "df_case = df_case[df_case[\"gene\"].isin(intersection_values)]\n",
    "df_case = df_case.sort_values(by=\"gene\")\n",
    "df_case = df_case.fillna(0)\n",
    "df_control = df_control[df_control[\"gene\"].isin(intersection_values)]\n",
    "df_control = df_control.sort_values(by=\"gene\")\n",
    "df_control = df_control.fillna(0)\n",
    "df_case.reset_index(drop=True, inplace=True)\n",
    "df_control.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rows must match in order to do index based math\n",
    "assert df_case[\"gene\"].equals(df_control[\"gene\"]), \"Case and control dataframe indices do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Initializing empty dataframes to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_results_1 = pd.DataFrame()\n",
    "fraction_results_2 = pd.DataFrame(columns=df_case.columns[1:].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Calculating desired variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have passed only 1 file it will make expected_ratio to be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_ratio = case_count / control_count\n",
    "df_case.reset_index(drop=True, inplace=True)\n",
    "df_control.reset_index(drop=True, inplace=True)\n",
    "columns_to_add = df_case.columns[1:]\n",
    "\n",
    "# Calculate the mean of the case and control dataframes\n",
    "df_case_mean = df_case.mean()\n",
    "df_control_mean = df_control.mean()\n",
    "\n",
    "num_columns = df_case.shape[1]\n",
    "\n",
    "print(\"Case means \\n{0}\\nControl means \\n{1}\".format(df_case_mean, df_control_mean))\n",
    "print(\"Expected ratio cases / controls: {0}, log2 {1}\".format(expected_ratio, np.log2(expected_ratio)))\n",
    "print(\"Expected ratio cases / controls by group (log2): \\n {0}\".format(np.log2(df_case_mean / df_control_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisible columns, look at the ratios grossly\n",
    "divison_result_gross = df_case[columns_to_add] / df_control[columns_to_add]\n",
    "r = divison_result_gross[divison_result_gross[:-1] > expected_ratio].dropna(how=\"all\")\n",
    "r[\"gene\"] = df_case[\"gene\"]  ## Do nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Random selection of indices for statistical test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array([np.random.choice(df_case.index, size=case_genes_length, replace=False) for _ in range(iterations)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Taking sum for columns against selected indices for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of total variants for the case and control groups using the sampled indices\n",
    "total_variants_case = np.array([df_case.iloc[idx, 1:].sum().to_numpy() for idx in indices])\n",
    "total_variants_control = np.array([df_control.iloc[idx, 1:].sum().to_numpy() for idx in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what a single burden event looks like\n",
    "total_variants_case\n",
    "total_variants_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Ratios vector for each column based on given condition to include sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_vector = np.where(np.logical_and(total_variants_case > 1, total_variants_control > 1),\\\n",
    "                total_variants_case / total_variants_control,\\\n",
    "                np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numer of iterations and column number can be seen in shape\n",
    "ratios_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where sum is less than 1 NaN will be placed for the ratio in that\n",
    "ratios_vector[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Satisfying below statistical condition to get burden events\n",
    "Low variant count events are not statistically significants.\n",
    "I.e. gene sets containing only a few variants or variants in only one gene are excluded.\n",
    "High variant burdens are expected between impactful genes in the different groups.\n",
    "\n",
    "\n",
    "\n",
    "1. $$ \\log_2\\left(\\frac{\\text{ratios\\_vector}}{\\text{expected\\_ratio}}\\right) > log2(99th\\_percentile) $$\n",
    "\n",
    "\n",
    "2. $$ \\text{total\\_variants\\_case} > \\text{case\\_genes\\_length} $$\n",
    "\n",
    "\n",
    "3. $$ \\text{total\\_variants\\_control} > \\text{case\\_genes\\_length} $$\n",
    "\n",
    "4. $$ \\text{ Nonzero values total\\_variants\\_control} > 1 $$\n",
    "\n",
    "5. $$ \\text{ Nonzero values total\\_variants\\_case} > 1 $$\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove rows where there are only single values in a burden event (i.e. [0, 0, 0, 0.4])\n",
    "# Because we are looking for interactions between genes\n",
    "def count_zeros(arr):\n",
    "    return np.greater_equal(sum(1 for x in arr if (x == 0 or np.isnan(x))), combination_length-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_results_tmp = pd.DataFrame(ratios_vector, columns=df_case.columns[1:].tolist())\n",
    "\n",
    "complex_condition = (\n",
    "    (np.log2(ratios_vector/expected_ratio) > 0.2) & # Early filtering to reduce about 75% of data\n",
    "    (total_variants_case > case_genes_length) &\n",
    "    (total_variants_control > case_genes_length) &\n",
    "    (np.count_nonzero(~np.isnan(total_variants_control)) > 1) &\n",
    "    (np.count_nonzero(~np.isnan(total_variants_case)) > 1)\n",
    "                    ).T.flatten()\n",
    "\n",
    "gene = np.array([df_case.gene[idx].to_numpy() for idx in indices])\n",
    "gene = np.tile(gene, (len(df_case.columns[1:].tolist()),1))\n",
    "case = np.array([df_case.iloc[idx, 1:].to_numpy().T for idx in indices]).transpose((1, 0, 2))\n",
    "control = np.array([df_control.iloc[idx, 1:].to_numpy().T for idx in indices]).transpose((1, 0, 2))\n",
    "\n",
    "case = case.reshape((-1, case.shape[-1]))\n",
    "control = control.reshape((-1, control.shape[-1]))\n",
    "case_control = case/control\n",
    "gene_case_control = np.dstack((gene, case_control)) # Make a nested object combining ratios to genes, exploded later in section 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_results_1 = pd.DataFrame()\n",
    "fraction_results_1['frequency_bin'] = np.repeat(fraction_results_tmp.columns, len(fraction_results_tmp))\n",
    "fraction_results_1['burden_ratio'] = fraction_results_tmp.to_numpy().T.flatten()\n",
    "fraction_results_1[\"burden_ratio_norm\"] = fraction_results_1['burden_ratio'].div(expected_ratio)\n",
    "fraction_results_1[\"burden_ratio_norm_log2\"] = np.log2(fraction_results_1['burden_ratio_norm'])\n",
    "fraction_results_1['gene'] = list(gene)\n",
    "fraction_results_1['case'] = list(case)\n",
    "fraction_results_1['control'] = list(control)\n",
    "fraction_results_1['case_control'] = list(case_control)\n",
    "fraction_results_1['case_control_gene'] = list(gene_case_control)\n",
    "\n",
    "# Filter out a large amount of low ratio or low variant count burdens\n",
    "fraction_results_1 = fraction_results_1[complex_condition].reset_index(drop=True)\n",
    "\n",
    "### THIS WILL FILTER SINGLE GENE EVENTS\n",
    "fraction_results_1 = fraction_results_1[~fraction_results_1[\"case_control\"].apply(count_zeros)]\n",
    "### THIS WILL FILTER SINGLE GENE EVENTS\n",
    "\n",
    "\n",
    "fraction_results_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify True and False condition indexes\n",
    "#print(list(complex_condition))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Storing Dataframe\n",
    "Normalise ratios with the expected ratio (expected mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_results_2 = pd.DataFrame(ratios_vector/expected_ratio, columns=df_case.columns[1:].tolist())\n",
    "if config[\"store_data\"]:\n",
    "    fraction_results_2.to_pickle(\"{0}_{1}_{2}_forgraph.pkl\".format(case_count, control_count, iterations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Plotting the burden events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fraction_results_2 = pd.read_pickle(\"{0}_{1}_{2}_forgraph.pkl\".format(case_count, control_count, iterations))\n",
    "df_99 = pd.DataFrame([\"frequency_bin\", \"99th_quantile\"])\n",
    "fig, axs = plt.subplots(\n",
    "    len(fraction_results_2.columns),\n",
    "    1,\n",
    "    sharex=\"none\",\n",
    "    tight_layout=False,\n",
    "    figsize=(12, 24),\n",
    "    facecolor='xkcd:mint green',\n",
    ")\n",
    "i = 0\n",
    "for frequency_column in fraction_results_2.columns:\n",
    "    fraction_results_2[frequency_column].dropna(inplace=True)\n",
    "\n",
    "    if fraction_results_2[frequency_column].any():\n",
    "        # Average sample normalization enrichment ratios for \"likely impactful\" and \"likely non-impactful\" genes\n",
    "        q_avg = np.divide(\n",
    "            np.sum(df_case[df_case.gene.isin(rv_genes)][frequency_column]),\n",
    "            np.sum(df_control[df_control.gene.isin(rv_genes)][frequency_column]),)\n",
    "        q_avg_control_group = np.divide(\n",
    "            np.sum(df_case[df_case.gene.isin(neg_control_genes)][frequency_column]),\n",
    "            np.sum(\n",
    "                df_control[df_control.gene.isin(neg_control_genes)][frequency_column]),)\n",
    "        print(\n",
    "            \"Impact group (av-norm. ): {0}, case_genes_enrichment: {1}, control_genes_enrichment: {2}\".format(\n",
    "                frequency_column, q_avg, q_avg_control_group\n",
    "            )\n",
    "        )\n",
    "        fraction_results_2[frequency_column + \"log2\"] = np.log2(\n",
    "            fraction_results_2[frequency_column]).dropna()\n",
    "\n",
    "\n",
    "        # Unused block\n",
    "        mu, std = sp.norm.fit(fraction_results_2[frequency_column].dropna())\n",
    "        percentile_99 = np.percentile(fraction_results_2[frequency_column + \"log2\"].dropna(), 99)\n",
    "        xmin, xmax = (\n",
    "            fraction_results_2[frequency_column].min(),\n",
    "            fraction_results_2[frequency_column].dropna().max(),\n",
    "        )\n",
    "        x = np.linspace(mu - 3 * std, mu + 3*std, 100)\n",
    "        _, bins, _ = axs[i].hist(\n",
    "            fraction_results_2[frequency_column + \"log2\"],\n",
    "            density=False,\n",
    "            log=False,\n",
    "            histtype=\"stepfilled\",\n",
    "            stacked=True,\n",
    "            bins=500,\n",
    "        )\n",
    "        p = sp.norm.pdf(bins, mu, std)\n",
    "        axs[i].set_title(\n",
    "            \"{0}: mean_enrichment={1} positive_genes={2} negative_genes={3} 99th percentile (purple)={4}\".format(\n",
    "                fraction_results_2[frequency_column].name  + \"_log2\",\n",
    "                np.round(fraction_results_2[frequency_column].mean(), 2),\n",
    "                np.round(np.log2(q_avg), 2),\n",
    "                np.round(np.log2(q_avg_control_group), 2),\n",
    "                np.round(percentile_99, 2)\n",
    "                )\n",
    "        )\n",
    "        axs[i].axvline(percentile_99, color=\"purple\")\n",
    "        df_99[frequency_column] = np.round(percentile_99, 2)\n",
    "        i +=1\n",
    "plt.show()\n",
    "print(\"Done {0} iterations\".format(iterations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Transform the 99th percentiles into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_99 = df_99.drop(df_99.index[0])\n",
    "df_99 = df_99.T\n",
    "df_99.columns = df_99.iloc[0]\n",
    "df_99 = df_99[1:]\n",
    "\n",
    "# See the 99th percentile in log2 for all simulations without the filters applied:\n",
    "df_99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 Plotting high burden events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take in high value burden events and filter out genes from gene sets that actually contribute to the burden event,\n",
    "keep only impactful (i.e. above 99th percentile) events and plot the times the gene has appeared in burden events against highest event, keep only genes that appear more than 40 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_results_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df = fraction_results_1\n",
    "df[\"impactful_bool\"] = df.apply(lambda row: row.loc[\"burden_ratio_norm_log2\"] > df_99.loc[row.loc[\"frequency_bin\"]], axis=1) #slow\n",
    "df = df[df.impactful_bool]\n",
    "\n",
    "df = df.explode(\"case_control_gene\") # Slow due explode by size of gene_set\n",
    "\n",
    "df = df[~df[\"case_control_gene\"].apply(lambda x: any(pd.isna(case_control_gene) or case_control_gene == 0 for case_control_gene in x))]\n",
    "df[[\"impactful_gene\", \"impactful_burden\"]] = df[\"case_control_gene\"].tolist()\n",
    "# Add some summary statistics about burden events\n",
    "df2 = df.merge(df.groupby([\"frequency_bin\", \"impactful_gene\"])[\"burden_ratio\"].aggregate([pd.Series.count]).reset_index())\n",
    "# Filter out rare occurrences of high burden (correlating to miniscule bumps above 99th percentile on the main plot)\n",
    "df2 = df2[df2[\"count\"]>30]\n",
    "df2.sort_values(\"burden_ratio_norm_log2\", ascending=False, inplace=True)\n",
    "df2.drop_duplicates(subset=\"impactful_gene\", inplace=True)\n",
    "df2.sort_values(\"frequency_bin\", inplace=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Save high value burden events data to csv"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data\n",
    "if config[\"store_data\"]:\n",
    "    df.to_csv(\"{0}_{1}_{2}.csv\".format(case_count, control_count, iterations))\n",
    "    df.to_pickle(\"{0}_{1}_{2}.pkl\".format(case_count, control_count, iterations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2  Plot relevant genes in each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle(\"{0}_{1}_{2}.pkl\".format(case_count, control_count, iterations))\n",
    "\n",
    "# Plot data, output is max 12 plots for every frequency bin.\n",
    "genes = []\n",
    "for frequency_column in fraction_results_2.columns:\n",
    "    filtered_df = df2[df2[\"frequency_bin\"] == frequency_column]\n",
    "    if filtered_df.shape[0] > 0:\n",
    "        #plt.scatter(data=filtered_df[\"gene\"], x=filtered_df[\"case_control\"], y=filtered_df[\"burden_ratio\"])\n",
    "\n",
    "        ax = filtered_df.plot(x='count', y='burden_ratio_norm_log2', kind='scatter', figsize=(5, 5),\n",
    "                              title=frequency_column, legend=\"impactful_gene\", facecolor='white', marker=\" \")\n",
    "        texts = []\n",
    "        filtered_df[['count', 'burden_ratio_norm_log2', 'impactful_gene']].apply(lambda x: texts.append(ax.text(*x, color=\"red\")), axis=1)\n",
    "        adjust_text(texts, arrowprops=dict(arrowstyle=\"-\", color='b', lw=0.2), time_lim=5, ax=ax)\n",
    "        genes.append([frequency_column, texts])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful to see g:Profiles for these genes\n",
    "for name, graph in genes:\n",
    "    print(name)\n",
    "    for text in graph:\n",
    "        print(text.get_text())\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "important_genes = [\"GLE1\", \"TWIST1\", \"FANCB\", \"RDH12\", \"NPR3\", \"FAAH2\", \"XPNPEP3\", \"AGA\", \"DIP2B\", \"SNIP1\", \"NCKAP1\"]\n",
    "#df = df[df[\"impactful_gene\"].apply(lambda x: x in important_genes)]\n",
    "\n",
    "import itertools\n",
    "for pair in (list(itertools.combinations(df[\"impactful_gene\"], 2))):\n",
    "    print(\"{0},{1}\".format(pair, sum(set(pair).issubset(set(row)) for row in df['gene'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
